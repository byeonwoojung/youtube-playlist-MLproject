"""
ì˜¤ë””ì˜¤ ì •ëŸ‰ì  í”¼ì²˜ ì¶”ì¶œ ëª¨ë“ˆ

YouTube URLì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ì •ëŸ‰ì  í”¼ì²˜ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤:
- BPM (í…œí¬)
- Pitch (ìŒë†’ì´) 
- Energy (ì—ë„ˆì§€)
- Spectral Centroid (ìŒìƒ‰ ë°ê¸°)
- Speech Rate (ë°œí™” ì†ë„)
- Initial Silence (ì´ˆê¸° ë¬´ìŒ)
"""

import os
import subprocess
import pandas as pd
import numpy as np
import librosa
from tqdm import tqdm
from urllib.parse import urlparse, parse_qs
from concurrent.futures import ProcessPoolExecutor, as_completed
import time
import ast

# í™˜ê²½ ì„¤ì •
os.environ["PATH"] = "/opt/homebrew/opt/ffmpeg/bin:" + os.environ["PATH"]
SAVE_DIR = "temp_audio"
TEMP_DIR = "../rawData/audio/tempAudio"
OUTPUT_FILE = "../rawData/audio/audio_quantitative.csv"
RETRY_OUTPUT_FILE = "../rawData/audio/audio_quantitative_errorRetry.csv"
FINAL_OUTPUT_FILE = "../rawData/audio/audio_quantitative_retry.csv"
os.makedirs(SAVE_DIR, exist_ok=True)
os.makedirs(TEMP_DIR, exist_ok=True)


# ========================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ========================================

def extract_video_id(url):
    """YouTube URLì—ì„œ video_id ì¶”ì¶œ"""
    parsed = urlparse(url)
    return parse_qs(parsed.query).get("v", [None])[0]


def load_audio_fast_ffmpeg(path, sr=22050):
    """FFmpegë¥¼ ì‚¬ìš©í•œ ë¹ ë¥¸ ì˜¤ë””ì˜¤ ë¡œë”©"""
    command = ["ffmpeg", "-i", path, "-f", "f32le", "-ac", "1", "-ar", str(sr), "-"]
    process = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL, check=True)
    return np.frombuffer(process.stdout, np.float32), sr


def get_audio_path(video_id):
    """ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ìƒì„±"""
    return os.path.join(SAVE_DIR, f"{video_id}.m4a")


# ========================================
# í”¼ì²˜ ì¶”ì¶œ í•¨ìˆ˜
# ========================================

def process_video(url):
    """
    ë‹¨ì¼ YouTube ë¹„ë””ì˜¤ ì²˜ë¦¬ (ë‹¤ìš´ë¡œë“œ + í”¼ì²˜ ì¶”ì¶œ)
    """
    video_id = extract_video_id(url)
    result = {
        "video_id": video_id, "url": url,
        "pitch_mean": None, "energy_mean": None, "centroid_mean": None,
        "bpm": None, "speech_rate": None, "initial_silence": None, "error": None
    }
    output_path = get_audio_path(video_id)

    try:
        command = [
            "yt-dlp", url, "-f", "bestaudio[ext=m4a]",
            "--download-sections", "*0-60", "--user-agent", "Mozilla/5.0",
            "--socket-timeout", "10", "--retries", "2",
            "-o", f"{SAVE_DIR}/{video_id}.%(ext)s"
        ]
        proc = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        
        if not os.path.exists(output_path):
            raise FileNotFoundError("m4a ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")

        y, sr = load_audio_fast_ffmpeg(output_path)

        # Pitch (ìŒë†’ì´)
        f0 = librosa.yin(y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'), sr=sr)
        result["pitch_mean"] = np.nanmean(f0)
        
        # Energy (ì—ë„ˆì§€)
        rms = librosa.feature.rms(y=y)
        result["energy_mean"] = np.mean(rms)
        
        # Spectral Centroid (ìŒìƒ‰ ë°ê¸°)
        result["centroid_mean"] = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))
        
        # BPM (í…œí¬) - ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜ë¨
        result["bpm"] = librosa.beat.beat_track(y=y, sr=sr)[0]
        
        # Speech Rate (ë°œí™” ì†ë„)
        result["speech_rate"] = len(librosa.onset.onset_detect(y=y, sr=sr, units='time'))
        
        # Initial Silence (ì´ˆê¸° ë¬´ìŒ)
        rms_vals = rms[0]
        result["initial_silence"] = librosa.frames_to_time(np.argmax(rms_vals > 0.01), sr=sr) if np.any(rms_vals > 0.01) else 60.0

    except subprocess.CalledProcessError as e:
        result["error"] = f"yt-dlp error: {e.stderr.decode(errors='ignore')[:300]}"
    except Exception as e:
        result["error"] = str(e)
    finally:
        try:
            os.remove(output_path)
        except:
            pass

    return result


# ========================================
# 1ë‹¨ê³„: ì „ì²´ ì˜ìƒ ì²˜ë¦¬
# ========================================

def main():
    """
    ì „ì²´ YouTube URL ì²˜ë¦¬
    """
    df = pd.read_csv('../rawData/youtubeInfo/allYoutubeInfo_themeFiltered.csv')
    video_data = [url for url in df["video_url"] if extract_video_id(url)]

    if os.path.exists(OUTPUT_FILE):
        processed_ids = set(pd.read_csv(OUTPUT_FILE)["video_id"])
    else:
        processed_ids = set()

    start = time.time()
    batch_results = []
    batch_count = 0

    with ProcessPoolExecutor(max_workers=8) as executor:
        futures = [
            executor.submit(process_video, url)
            for url in video_data if extract_video_id(url) not in processed_ids
        ]
        for i, f in enumerate(tqdm(as_completed(futures), total=len(futures), desc="Processing videos", dynamic_ncols=True, leave=True)):
            try:
                result = f.result()
                batch_results.append(result)

                if len(batch_results) >= 100:
                    temp_path = os.path.join(TEMP_DIR, f"batch_{batch_count:04d}.csv")
                    pd.DataFrame(batch_results).to_csv(
                        temp_path, index=False,
                        encoding="utf-8-sig", float_format="%.4f"
                    )
                    batch_results.clear()
                    batch_count += 1
            except Exception as e:
                print(f"[ERROR] {e}")

    if batch_results:
        temp_path = os.path.join(TEMP_DIR, f"batch_{batch_count:04d}.csv")
        pd.DataFrame(batch_results).to_csv(
            temp_path, index=False,
            encoding="utf-8-sig", float_format="%.4f"
        )

    print(f"\nâ± ì „ì²´ ì†Œìš” ì‹œê°„: {time.time() - start:.2f}ì´ˆ")


def merge_temp_batches():
    """
    ë°°ì¹˜ íŒŒì¼ ë³‘í•©
    """
    import glob

    temp_files = sorted(glob.glob(os.path.join(TEMP_DIR, "batch_*.csv")))
    if not temp_files:
        print("âš ï¸ ë³‘í•©í•  batch_*.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_all = pd.concat([pd.read_csv(f) for f in temp_files], ignore_index=True)
    df_all.to_csv(OUTPUT_FILE, index=False, encoding="utf-8-sig", float_format="%.4f")
    print(f"âœ… ë³‘í•© ì™„ë£Œ â†’ {OUTPUT_FILE} ì €ì¥ë¨")



# ========================================
# 2ë‹¨ê³„: ì—ëŸ¬ ì¬ì‹œë„
# ========================================

def retry_error_videos():
    """
    ì—ëŸ¬ ë°œìƒí•œ ì˜ìƒë§Œ ì¬ì‹œë„
    """
    df = pd.read_csv(OUTPUT_FILE)
    error_rows = df[df["error"].notnull()]

    print(f"ğŸ” ì¬ì²˜ë¦¬í•  ì˜ìƒ ìˆ˜: {len(error_rows)}")

    results = []
    for _, row in tqdm(error_rows.iterrows(), total=len(error_rows), desc="Retrying errors"):
        results.append(process_video(row["url"]))

    df_retry = pd.DataFrame(results)
    df_retry.to_csv(RETRY_OUTPUT_FILE, index=False, encoding="utf-8-sig", float_format="%.4f")
    print(f"âœ… ì¬ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ ì™„ë£Œ â†’ {RETRY_OUTPUT_FILE}")



# ========================================
# 3ë‹¨ê³„: í›„ì²˜ë¦¬
# ========================================

def postprocess_audio():
    """
    ì˜¤ë””ì˜¤ ì •ëŸ‰ì  í”¼ì²˜ í›„ì²˜ë¦¬
    
    1. ì›ë³¸ + ì¬ì‹œë„ CSV ë³‘í•©
    2. BPM ë¦¬ìŠ¤íŠ¸ ë¬¸ìì—´ â†’ ìˆ«ì ë³€í™˜
    3. ê²°ì¸¡ì¹˜ ì œê±°
    """
    # ë³‘í•©
    df_original = pd.read_csv(OUTPUT_FILE)
    df_retry = pd.read_csv(RETRY_OUTPUT_FILE)

    # retry ê²°ê³¼ì—ì„œ errorê°€ ì—†ëŠ” ë°ì´í„°ë§Œ ìœ ì§€
    df_retry_success = df_retry[df_retry["error"].isnull()]

    # video_id ê¸°ì¤€ìœ¼ë¡œ ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸
    df_updated = df_original.set_index("video_id").combine_first(df_retry_success.set_index("video_id")).reset_index()

    # í›„ì²˜ë¦¬
    # 1) bpm: ë¦¬ìŠ¤íŠ¸ê°€ ë¬¸ìì—´ í˜•íƒœë¡œ ëœ ê²ƒ -> ë¦¬ìŠ¤íŠ¸í™” ì‹œí‚¨ í›„, ìˆ«ìë§Œ ê°€ì ¸ì˜´
    # 2) ê²°ì¸¡ì¹˜ ìˆëŠ” í–‰ ì œê±°
    
    # bpm ë¬¸ìì—´ â†’ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬ í›„ ì²« ê°’ ì¶”ì¶œ
    df_updated['bpm'] = df_updated['bpm'].apply(
        lambda x: round(ast.literal_eval(x)[0], 4) if isinstance(x, str) and x.startswith('[') else x
    )

    # ì¤‘ìš” ì»¬ëŸ¼ ì •ì˜ (ë¶„ì„ì— ê¼­ í•„ìš”í•œ ì»¬ëŸ¼ë“¤)
    important_cols = ['bpm', 'pitch_mean', 'energy_mean', 'centroid_mean', 'speech_rate', 'initial_silence']

    # ì¤‘ìš” ì»¬ëŸ¼ ì¤‘ í•˜ë‚˜ë¼ë„ ê²°ì¸¡ì¹˜ê°€ ìˆìœ¼ë©´ ì œê±°
    df_cleaned = df_updated.dropna(subset=important_cols)

    # ì €ì¥
    df_cleaned.to_csv(FINAL_OUTPUT_FILE, encoding='utf-8-sig', index=False, float_format="%.4f")
    print(f"âœ… ê²°ì¸¡ì¹˜ ì œê±° í›„ ì €ì¥ ì™„ë£Œ: {len(df_updated)} â†’ {len(df_cleaned)} í–‰ ìœ ì§€ë¨")


# ========================================
# ë©”ì¸ ì‹¤í–‰
# ========================================

if __name__ == "__main__":
    # 1ë‹¨ê³„: ì „ì²´ ì˜ìƒ ì¶”ì¶œ
    print("\n[1/3] ì „ì²´ ì˜ìƒ ì˜¤ë””ì˜¤ í”¼ì²˜ ì¶”ì¶œ...")
    main()
    merge_temp_batches()
    
    # 2ë‹¨ê³„: ì—ëŸ¬ ì¬ì‹œë„
    print("\n[2/3] ì—ëŸ¬ ì˜ìƒ ì¬ì‹œë„...")
    retry_error_videos()
    
    # 3ë‹¨ê³„: í›„ì²˜ë¦¬ (ë³‘í•© + BPM íŒŒì‹± + ê²°ì¸¡ì¹˜ ì œê±°)
    print("\n[3/3] í›„ì²˜ë¦¬ (ë³‘í•© + BPM íŒŒì‹± + ê²°ì¸¡ì¹˜ ì œê±°)...")
    postprocess_audio()
    
    print("\n" + "=" * 60)
    print("âœ… ì „ì²´ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ!")
    print("=" * 60)


