"""
ì¸ë„¤ì¼ í”¼ì²˜ ì¶”ì¶œ ëª¨ë“ˆ

YouTube ì¸ë„¤ì¼ ì´ë¯¸ì§€ë¡œë¶€í„° ë‹¤ì–‘í•œ ê°ì„±ì  í”¼ì²˜ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤:
- í…ìŠ¤íŠ¸ ë¹„ìœ¨ (OCR ê¸°ë°˜)
- ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„° ë¹„ìœ¨ (CSS3 45ê°œ í´ëŸ¬ìŠ¤í„°)
- ë°ê¸° í‘œì¤€í¸ì°¨ (ëŒ€ë¹„)
- ì§ˆê° ë° ì„ ëª…ë„
- ê°ì²´ íƒì§€ (ì‚¬ëŒ, ë™ë¬¼, ì• ë‹ˆë©”ì´ì…˜, í’ê²½)
- ìƒ‰ìƒ í…Œë§ˆ ë§¤ì¹­
- ì–¼êµ´ íƒì§€ ë° ì •ë©´ ì–¼êµ´ ë¶„ì„

ì°¸ê³ : ì˜¤ë””ì˜¤ ê°ì • í”¼ì²˜(Audio Emotional)ëŠ” audio_qualitative.pyì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤.
      - happy, sad, angry, fear, surprise, disgust, neutral

âš ï¸ ëª¨ë¸ë§ì—ì„œ ì œì™¸ëœ í”¼ì²˜:
   - colorsDaily_matchScore, colorsSensibility_matchScore 
     â†’ ëŒ€ì‹  ì´ ë‘˜ì˜ ìµœëŒ“ê°’ì¸ colorsTheme_matchScore ì‚¬ìš©
   - brightness_weightedStd (ëŒ€ì‹  brightness_weightedStd_scaledSigmoid ì‚¬ìš©)
   - texture_sharpness_scaled (ëŒ€ì‹  ì›ë³¸ texture_sharpness ì‚¬ìš©)
   - colorsCluster_0~44 ì „ì²´ (ëª¨ë¸ë§ ì‹œ ìƒìœ„ 10ê°œë§Œ colorRank_1~10ìœ¼ë¡œ ë³€í™˜)
"""

import os
import sys
import cv2
import numpy as np
import pandas as pd
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# ìƒëŒ€ ê²½ë¡œ importë¥¼ ìœ„í•œ ì„¤ì •
sys.path.append(str(Path(__file__).parent.parent))

# Google Vision API ì„¤ì •
from google.cloud import vision
import re
from concurrent.futures import ThreadPoolExecutor
import threading
from functools import lru_cache

# ìƒ‰ìƒ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
import webcolors
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from collections import defaultdict

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ import
try:
    from utils.helpers import setup_gpu, save_csv_safely
except ImportError:
    print("âš  utils.helpersë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    def setup_gpu():
        return {"device": "cpu"}
    
    def save_csv_safely(df, filepath, encoding="utf-8-sig"):
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        df.to_csv(filepath, index=False, encoding=encoding)
        return True


# ========================================
# 1. í…ìŠ¤íŠ¸ í”¼ì²˜ ì¶”ì¶œ (OCR)
# ========================================

class ThumbnailTextExtractor:
    """
    ì¸ë„¤ì¼ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë¹„ìœ¨ ì¶”ì¶œ
    Google Cloud Vision API ì‚¬ìš©
    """
    
    def __init__(self, credentials_path: str, max_workers: int = 4):
        """
        Args:
            credentials_path: Google Cloud ì¸ì¦ JSON íŒŒì¼ ê²½ë¡œ
            max_workers: ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜
        """
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = credentials_path
        self.client = vision.ImageAnnotatorClient()
        self.max_workers = max_workers
        self.lock = threading.Lock()
    
    @staticmethod
    def is_valid_text(text: str) -> bool:
        """ìœ íš¨í•œ í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸ (í•œê¸€, ì˜ë¬¸, ìˆ«ì í¬í•¨)"""
        return re.search(r"[ê°€-í£a-zA-Z0-9]", text) is not None
    
    @staticmethod
    def expand_bbox(xs: List, ys: List, img_w: int, img_h: int, ratio: float = 0.3) -> Tuple[int, int, int, int]:
        """Bounding box í™•ì¥"""
        x1, x2 = min(xs), max(xs)
        y1, y2 = min(ys), max(ys)
        w = x2 - x1
        h = y2 - y1
        x1_exp = max(0, int(x1 - w * ratio))
        x2_exp = min(img_w, int(x2 + w * ratio))
        y1_exp = max(0, int(y1 - h * ratio))
        y2_exp = min(img_h, int(y2 + h * ratio))
        return x1_exp, x2_exp, y1_exp, y2_exp
    
    def vision_ocr_optimized(self, img: np.ndarray) -> Tuple[List, set]:
        """ìµœì í™”ëœ OCR (í•œ ë²ˆì˜ API í˜¸ì¶œë¡œ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ)"""
        _, img_bytes = cv2.imencode(".jpg", img)
        content = img_bytes.tobytes()
        image = vision.Image(content=content)
        
        with self.lock:  # API í˜¸ì¶œ ë™ê¸°í™”
            response = self.client.text_detection(image=image)
        
        texts = response.text_annotations
        results = []
        valid_texts = set()
        
        if texts:
            for text in texts[1:]:
                if self.is_valid_text(text.description.strip()):
                    valid_texts.add(text.description.strip())
                    box = [(v.x, v.y) for v in text.bounding_poly.vertices]
                    while len(box) < 4:
                        box.append(box[-1])
                    results.append((box, text.description.strip()))
        
        return results, valid_texts
    
    def process_single_image(self, img_path: str) -> Dict:
        """ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë¹„ìœ¨ ì¶”ì¶œ"""
        try:
            orig_img = cv2.imread(img_path)
            if orig_img is None:
                return {"video_id": Path(img_path).stem[:11], "text_ratio": 0.0, "error": "ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨"}
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (2ë°° í™•ëŒ€)
            img_color = cv2.resize(orig_img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
            img_h, img_w = img_color.shape[:2]
            
            # OCR ìˆ˜í–‰
            all_results, valid_texts = self.vision_ocr_optimized(img_color)
            
            # ë§ˆìŠ¤í¬ ìƒì„±
            mask = np.zeros(img_color.shape[:2], dtype=np.uint8)
            
            for bbox, text in all_results:
                if len(text) == 0 or not self.is_valid_text(text):
                    continue
                pts = np.array(bbox, dtype=np.int32)
                cv2.fillPoly(mask, [pts], 255)
            
            # í…ìŠ¤íŠ¸ ë¹„ìœ¨ ê³„ì‚°
            text_pixels = cv2.countNonZero(mask)
            total_pixels = mask.shape[0] * mask.shape[1]
            text_ratio = (text_pixels / total_pixels) * 100 if total_pixels > 0 else 0
            
            return {
                "video_id": Path(img_path).stem[:11],
                "text_ratio": round(text_ratio, 2)
            }
        except Exception as e:
            return {"video_id": Path(img_path).stem[:11], "text_ratio": 0.0, "error": str(e)}
    
    def extract_batch(self, image_folder: str, output_csv: str) -> pd.DataFrame:
        """ë°°ì¹˜ë¡œ ì´ë¯¸ì§€ í´ë” ì²˜ë¦¬"""
        image_files = list(Path(image_folder).glob("*.jpg")) + list(Path(image_folder).glob("*.png"))
        
        results = []
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = [executor.submit(self.process_single_image, str(img)) for img in image_files]
            
            for future in tqdm(futures, desc="ğŸ“ í…ìŠ¤íŠ¸ ë¹„ìœ¨ ì¶”ì¶œ"):
                result = future.result()
                if "error" not in result or result.get("text_ratio", 0) > 0:
                    results.append(result)
        
        df = pd.DataFrame(results)
        save_csv_safely(df, output_csv)
        print(f"âœ… í…ìŠ¤íŠ¸ í”¼ì²˜ ì¶”ì¶œ ì™„ë£Œ: {len(df)}ê°œ")
        return df


# ========================================
# 2. ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„° í”¼ì²˜ ì¶”ì¶œ
# ========================================

class ThumbnailColorExtractor:
    """
    ì¸ë„¤ì¼ ìƒ‰ìƒì„ CSS3 45ê°œ í´ëŸ¬ìŠ¤í„°ë¡œ ë¶„ë¥˜í•˜ê³  ë©´ì  ë¹„ìœ¨ ê³„ì‚°
    """
    
    def __init__(self, n_clusters: int = 45):
        """
        Args:
            n_clusters: ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ (ê¸°ë³¸ 45ê°œ)
        """
        self.n_clusters = n_clusters
        self.kmeans_model = None
        self.rgb_to_cluster_cache = {}
        self._initialize_color_clusters()
    
    def _initialize_color_clusters(self):
        """CSS3 ìƒ‰ìƒì„ LAB ê³µê°„ì—ì„œ K-Means í´ëŸ¬ìŠ¤í„°ë§"""
        # CSS3 ìƒ‰ìƒ ì¶”ì¶œ
        css3_names = list(webcolors.CSS3_NAMES_TO_HEX.keys())
        css3_hex_codes = list(webcolors.CSS3_NAMES_TO_HEX.values())
        
        # HEX â†’ RGB ë³€í™˜
        def hex_to_rgb(hx):
            return tuple(int(hx[i:i+2], 16) for i in (1, 3, 5))
        
        css3_rgb = [hex_to_rgb(hx) for hx in css3_hex_codes]
        css3_rgb_np = np.array(css3_rgb, dtype=np.uint8).reshape(-1, 1, 3)
        
        # RGB â†’ LAB ë³€í™˜
        css3_lab_np = cv2.cvtColor(css3_rgb_np, cv2.COLOR_RGB2LAB).reshape(-1, 3).astype(np.float32)
        
        # K-Means í´ëŸ¬ìŠ¤í„°ë§
        self.kmeans_model = KMeans(n_clusters=self.n_clusters, random_state=42, n_init='auto')
        css3_labels = self.kmeans_model.fit_predict(css3_lab_np)
        
        # ìˆ˜ë™ í´ëŸ¬ìŠ¤í„° ì¡°ì • (í•™íšŒ ë…¼ë¬¸ ê¸°ì¤€)
        manual_assignments = {
            'steelblue': 27, 'rosybrown': 39, 'darkkhaki': 30,
            'aquamarine': 14, 'paleturquoise': 22, 'thistle': 44,
            'cadetblue': 22, 'gray': 29, 'grey': 29,
            'lightsteelblue': 9, 'indigo': 38, 'mistyrose': 43
        }
        
        name_to_index = {name: idx for idx, name in enumerate(css3_names)}
        for color_name, new_cluster in manual_assignments.items():
            idx = name_to_index[color_name]
            css3_labels[idx] = new_cluster
        
        # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ ì¬ê³„ì‚°
        css3_centers_lab = self.kmeans_model.cluster_centers_.astype(np.float32)
        target_clusters = sorted(set(manual_assignments.values()))
        
        for cluster_id in target_clusters:
            member_idxs = np.where(css3_labels == cluster_id)[0]
            member_labs = css3_lab_np[member_idxs]
            css3_centers_lab[cluster_id] = member_labs.mean(axis=0)
        
        self.kmeans_model.cluster_centers_ = css3_centers_lab
        print(f"âœ“ ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„° ì´ˆê¸°í™” ì™„ë£Œ: {self.n_clusters}ê°œ")
    
    def get_cluster_id_from_rgb(self, rgb: Tuple[int, int, int]) -> int:
        """RGB í”½ì…€ê°’ì„ í´ëŸ¬ìŠ¤í„° IDë¡œ ë³€í™˜ (ìºì‹± ì‚¬ìš©)"""
        if rgb in self.rgb_to_cluster_cache:
            return self.rgb_to_cluster_cache[rgb]
        
        rgb_arr = np.array([[list(rgb)]], dtype=np.uint8)
        lab = cv2.cvtColor(rgb_arr, cv2.COLOR_RGB2LAB).reshape(-1, 3).astype(np.float32)
        cluster_id = int(self.kmeans_model.predict(lab)[0])
        self.rgb_to_cluster_cache[rgb] = cluster_id
        return cluster_id
    
    def extract_color_ratios(self, img_path: str) -> Dict:
        """
        ì´ë¯¸ì§€ì—ì„œ ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„°ë³„ ë©´ì  ë¹„ìœ¨ ì¶”ì¶œ
        
        Returns:
            - colorsCluster_0 ~ colorsCluster_44 (45ê°œ ì»¬ëŸ¼)
            - total_colors: ë“±ì¥í•œ ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜
        """
        try:
            img = cv2.imread(img_path)
            if img is None:
                raise ValueError("ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")
            
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            h, w, _ = img.shape
            total_pixels = h * w
            cluster_counts = np.zeros(self.n_clusters, dtype=int)
            
            # ëª¨ë“  í”½ì…€ì— ëŒ€í•´ í´ëŸ¬ìŠ¤í„° í• ë‹¹
            for y in range(h):
                for x in range(w):
                    rgb = tuple(img[y, x])
                    cluster_id = self.get_cluster_id_from_rgb(rgb)
                    cluster_counts[cluster_id] += 1
            
            # ë¹„ìœ¨ ê³„ì‚° (ì†Œìˆ˜ì  ë„·ì§¸ìë¦¬)
            cluster_ratios = cluster_counts / total_pixels
            
            result = {"video_id": Path(img_path).stem[:11]}
            for i in range(self.n_clusters):
                result[f"colorsCluster_{i}"] = round(cluster_ratios[i], 4)
            
            # ì´ ìƒ‰ìƒ ìˆ˜ (ë¹„ìœ¨ì´ 0ë³´ë‹¤ í° í´ëŸ¬ìŠ¤í„° ê°œìˆ˜)
            result["total_colors"] = int(np.sum(cluster_ratios > 0))
            
            return result
        except Exception as e:
            print(f"âŒ ìƒ‰ìƒ ì¶”ì¶œ ì‹¤íŒ¨ ({img_path}): {e}")
            return None
    
    def extract_batch(self, image_folder: str, output_csv: str) -> pd.DataFrame:
        """ë°°ì¹˜ ì²˜ë¦¬"""
        image_files = list(Path(image_folder).glob("*.jpg")) + list(Path(image_folder).glob("*.png"))
        
        results = []
        for img_path in tqdm(image_files, desc="ğŸ¨ ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„° ë¶„ì„"):
            result = self.extract_color_ratios(str(img_path))
            if result:
                results.append(result)
        
        df = pd.DataFrame(results)
        save_csv_safely(df, output_csv)
        print(f"âœ… ìƒ‰ìƒ í”¼ì²˜ ì¶”ì¶œ ì™„ë£Œ: {len(df)}ê°œ")
        return df


# ========================================
# 3-6. ê¸°íƒ€ í”¼ì²˜ (ë°ê¸°, ì§ˆê°, ê°ì²´, í…Œë§ˆ ë§¤ì¹­)
# ========================================

class ThumbnailVisualExtractor:
    """
    ë°ê¸° ëŒ€ë¹„, ì§ˆê° ì„ ëª…ë„ ë“±ì˜ ì‹œê°ì  í”¼ì²˜ ì¶”ì¶œ
    + í‘œì¤€í™” ìŠ¤ì¼€ì¼ë§ í¬í•¨
    """
    
    @staticmethod
    def extract_brightness_weighted_std(
        colors_df: pd.DataFrame, 
        meta_csv_path: str
    ) -> pd.DataFrame:
        """
        ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„°ë³„ ëª…ì•”(ë°ê¸°) ê°€ì¤‘ í‘œì¤€í¸ì°¨ ê³„ì‚°
        + StandardScaler + Sigmoid í•¨ìˆ˜ ì ìš©
        
        Args:
            colors_df: thumbnails_colorsRatio.csv ë°ì´í„°í”„ë ˆì„ (colorsCluster_0~44 í¬í•¨)
            meta_csv_path: colorsCluster_meta.csv ê²½ë¡œ (V_hsv ê°’ í¬í•¨)
            
        Returns:
            brightness_weightedStd, brightness_weightedStd_scaledSigmoid ì»¬ëŸ¼ ì¶”ê°€ëœ DataFrame
        """
        # ë©”íƒ€ ë°ì´í„° ë¡œë“œ
        df_meta = pd.read_csv(meta_csv_path)
        V_vals = df_meta['V_hsv'].values
        
        def weighted_std(x, weights):
            """ê°€ì¤‘ í‘œì¤€í¸ì°¨ ê³„ì‚°"""
            x = np.array(x)
            weights = np.array(weights)
            average = np.sum(weights * x) / np.sum(weights)
            variance = np.sum(weights * (x - average) ** 2) / np.sum(weights)
            return np.sqrt(variance)
        
        # í´ëŸ¬ìŠ¤í„° ì»¬ëŸ¼ëª…
        ratio_cols = [f'colorsCluster_{i}' for i in range(len(V_vals))]
        
        # ê°€ì¤‘ í‘œì¤€í¸ì°¨ ê³„ì‚°
        brightness_weighted_std = colors_df[ratio_cols].apply(
            lambda row: weighted_std(V_vals, row.values),
            axis=1
        )
        
        # StandardScaler + Sigmoid í•¨ìˆ˜ ì ìš©
        scaler = StandardScaler()
        std_scaled = scaler.fit_transform(brightness_weighted_std.values.reshape(-1, 1))
        alpha = 1
        sigmoid_vals = 1 / (1 + np.exp(-alpha * std_scaled))
        
        result_df = colors_df[['video_id']].copy()
        result_df['brightness_weightedStd'] = brightness_weighted_std.round(4)
        result_df['brightness_weightedStd_scaledSigmoid'] = sigmoid_vals.flatten().round(4)
        
        return result_df
    
    @staticmethod
    def extract_texture_sharpness(img_path: str) -> Dict:
        """ì§ˆê° ë° ì„ ëª…ë„ ì¶”ì¶œ (Laplacian variance)"""
        try:
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                raise ValueError("ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")
            
            # Laplacianì„ ì´ìš©í•œ ì„ ëª…ë„ ì¸¡ì •
            laplacian_var = cv2.Laplacian(img, cv2.CV_64F).var()
            
            return {
                "video_id": Path(img_path).stem[:11],
                "texture_sharpness": round(laplacian_var, 2)
            }
        except Exception as e:
            return {"video_id": Path(img_path).stem[:11], "texture_sharpness": 0.0}
    
    def extract_batch_texture(self, image_folder: str, output_csv: str) -> pd.DataFrame:
        """
        ì§ˆê° í”¼ì²˜ ë°°ì¹˜ ì¶”ì¶œ + StandardScaler ì ìš©
        
        Returns:
            texture_sharpness, texture_sharpness_scaled ì»¬ëŸ¼ í¬í•¨
        """
        image_files = list(Path(image_folder).glob("*.jpg")) + list(Path(image_folder).glob("*.png"))
        
        results = []
        for img_path in tqdm(image_files, desc="ğŸŒ€ í…ìŠ¤ì²˜ ë¶„ì„"):
            results.append(self.extract_texture_sharpness(str(img_path)))
        
        df = pd.DataFrame(results)
        
        # StandardScaler ì ìš©
        if 'texture_sharpness' in df.columns:
            scaler = StandardScaler()
            df['texture_sharpness_scaled'] = scaler.fit_transform(
                df[['texture_sharpness']]
            ).flatten().round(4)
        
        save_csv_safely(df, output_csv)
        print(f"âœ… ì§ˆê° í”¼ì²˜ ì¶”ì¶œ ì™„ë£Œ: {len(df)}ê°œ")
        
        return df


# ========================================
# 4. ìƒ‰ìƒ í…Œë§ˆ ë§¤ì¹­ í”¼ì²˜
# ========================================

class ThumbnailColorThemeExtractor:
    """
    ì¸ë„¤ì¼ ìƒ‰ìƒê³¼ ì¼ìƒ/ê°ì„± í…Œë§ˆ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
    """
    
    def __init__(self, color_feeling_map_path: str):
        """
        Args:
            color_feeling_map_path: colorsFeelingMatch_map_dailySensScores.csv ê²½ë¡œ
        """
        self.color_feeling_map = pd.read_csv(color_feeling_map_path)
        self._prepare_lab_table()
    
    def _prepare_lab_table(self):
        """RGBë¥¼ LABìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í…Œì´ë¸” ì¤€ë¹„"""
        def rgb_to_lab_row(row):
            rgb = np.uint8([[[row['R'], row['G'], row['B']]]])
            lab = cv2.cvtColor(rgb, cv2.COLOR_RGB2LAB)[0][0]
            return pd.Series({'L_lab': lab[0], 'A_lab': lab[1], 'B_lab': lab[2]})
        
        self.color_feeling_map[['L_lab', 'A_lab', 'B_lab']] = self.color_feeling_map.apply(
            rgb_to_lab_row, axis=1
        )
        
        self.lab_values = self.color_feeling_map[['L_lab', 'A_lab', 'B_lab']].values.astype(np.float32)
        self.score_daily_vals = self.color_feeling_map['daily_score'].values
        self.score_sens_vals = self.color_feeling_map['sensibility_score'].values
        self.lab_score_cache = {}
    
    def compute_matching_scores_with_cache(self, img_lab: np.ndarray) -> Tuple[float, float]:
        """
        ì´ë¯¸ì§€ì˜ ëª¨ë“  í”½ì…€ì— ëŒ€í•´ ê°€ì¥ ê°€ê¹Œìš´ ìƒ‰ìƒì˜ ì¼ìƒ/ê°ì„± ì ìˆ˜ í‰ê·  ê³„ì‚°
        
        Returns:
            (daily_matchScore, sensibility_matchScore)
        """
        H, W, _ = img_lab.shape
        flattened = img_lab.reshape(-1, 3)
        
        matched_daily = []
        matched_sens = []
        
        for pix_lab in flattened:
            pix_key = tuple(pix_lab)
            
            if pix_key in self.lab_score_cache:
                daily, sens = self.lab_score_cache[pix_key]
            else:
                dists = np.linalg.norm(self.lab_values - pix_lab, axis=1)
                idx = np.argmin(dists)
                daily = self.score_daily_vals[idx]
                sens = self.score_sens_vals[idx]
                self.lab_score_cache[pix_key] = (daily, sens)
            
            matched_daily.append(daily)
            matched_sens.append(sens)
        
        return np.mean(matched_daily), np.mean(matched_sens)
    
    def extract_theme_scores(self, img_path: str) -> Dict:
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ìƒ‰ìƒ í…Œë§ˆ ë§¤ì¹­ ì ìˆ˜ ì¶”ì¶œ
        
        Returns:
            - colorsDaily_matchScore
            - colorsSensibility_matchScore
            - colorsTheme_matchScore (ë‘˜ ì¤‘ í° ê°’)
        """
        try:
            img = cv2.imread(img_path)
            if img is None:
                raise ValueError("ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")
            
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img_lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)
            
            score_d, score_s = self.compute_matching_scores_with_cache(img_lab)
            
            return {
                'video_id': Path(img_path).stem[:11],
                'colorsDaily_matchScore': round(score_d, 4),
                'colorsSensibility_matchScore': round(score_s, 4),
                'colorsTheme_matchScore': round(max(score_d, score_s), 4)
            }
        except Exception as e:
            print(f"âŒ í…Œë§ˆ ë§¤ì¹­ ì‹¤íŒ¨ ({img_path}): {e}")
            return None
    
    def extract_batch(self, image_folder: str, output_csv: str) -> pd.DataFrame:
        """ë°°ì¹˜ ì²˜ë¦¬"""
        image_files = list(Path(image_folder).glob("*.jpg")) + list(Path(image_folder).glob("*.png"))
        
        results = []
        for img_path in tqdm(image_files, desc="ğŸ¨ ìƒ‰ìƒ í…Œë§ˆ ë§¤ì¹­"):
            result = self.extract_theme_scores(str(img_path))
            if result:
                results.append(result)
        
        df = pd.DataFrame(results)
        save_csv_safely(df, output_csv)
        print(f"âœ… ìƒ‰ìƒ í…Œë§ˆ ë§¤ì¹­ ì™„ë£Œ: {len(df)}ê°œ")
        
        return df


# ========================================
# ë©”ì¸ í†µí•© í´ë˜ìŠ¤
# ========================================

class ThumbnailFeatureExtractor:
    """
    ëª¨ë“  ì¸ë„¤ì¼ í”¼ì²˜ë¥¼ í†µí•© ê´€ë¦¬í•˜ëŠ” ë©”ì¸ í´ë˜ìŠ¤
    """
    
    def __init__(self, google_credentials_path: Optional[str] = None):
        """
        Args:
            google_credentials_path: Google Cloud Vision API ì¸ì¦ íŒŒì¼ (í…ìŠ¤íŠ¸ ì¶”ì¶œìš©)
        """
        self.google_credentials_path = google_credentials_path
        self.gpu_info = setup_gpu()
        print(f"âœ“ GPU ì„¤ì •: {self.gpu_info['device']}")
    
    def extract_all_features(self, 
                            image_folder: str, 
                            output_dir: str,
                            extract_text: bool = True,
                            extract_colors: bool = True,
                            extract_visual: bool = True):
        """
        ëª¨ë“  ì¸ë„¤ì¼ í”¼ì²˜ë¥¼ í•œ ë²ˆì— ì¶”ì¶œ
        
        Args:
            image_folder: ì¸ë„¤ì¼ ì´ë¯¸ì§€ í´ë”
            output_dir: ê²°ê³¼ CSV ì €ì¥ ë””ë ‰í† ë¦¬
            extract_text: í…ìŠ¤íŠ¸ ë¹„ìœ¨ ì¶”ì¶œ ì—¬ë¶€
            extract_colors: ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„° ì¶”ì¶œ ì—¬ë¶€
            extract_visual: ë°ê¸°/ì§ˆê° ì¶”ì¶œ ì—¬ë¶€
        """
        os.makedirs(output_dir, exist_ok=True)
        
        results = {}
        
        # 1. í…ìŠ¤íŠ¸ ë¹„ìœ¨
        if extract_text and self.google_credentials_path:
            print("\n[1/3] í…ìŠ¤íŠ¸ ë¹„ìœ¨ ì¶”ì¶œ ì‹œì‘...")
            text_extractor = ThumbnailTextExtractor(self.google_credentials_path)
            results['text'] = text_extractor.extract_batch(
                image_folder, 
                os.path.join(output_dir, "thumbnails_text.csv")
            )
        
        # 2. ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„°
        if extract_colors:
            print("\n[2/3] ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„° ì¶”ì¶œ ì‹œì‘...")
            color_extractor = ThumbnailColorExtractor()
            results['colors'] = color_extractor.extract_batch(
                image_folder,
                os.path.join(output_dir, "thumbnails_colorsRatio.csv")
            )
        
        # 3. ë°ê¸°/ì§ˆê°
        if extract_visual:
            print("\n[3/3] ë°ê¸°/ì§ˆê° ì¶”ì¶œ ì‹œì‘...")
            visual_extractor = ThumbnailVisualExtractor()
            
            # ì§ˆê° í”¼ì²˜ ì¶”ì¶œ
            texture_df = visual_extractor.extract_batch_texture(
                image_folder,
                os.path.join(output_dir, "thumbnails_textureSharpness.csv")
            )
            results['texture'] = texture_df
            
            print("  âš ï¸  ë°ê¸° í”¼ì²˜ëŠ” ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„° ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            print("  â†’ ìƒ‰ìƒ í”¼ì²˜ ì¶”ì¶œ í›„ ë³„ë„ë¡œ ì‹¤í–‰í•˜ì„¸ìš”:")
            print("     brightness_df = ThumbnailVisualExtractor.extract_brightness_weighted_std(")
            print("         colors_df, 'path/to/colorsCluster_meta.csv')")
        
        print(f"\nâœ… ëª¨ë“  ì¸ë„¤ì¼ í”¼ì²˜ ì¶”ì¶œ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_dir}")
        
        return results


# ========================================
# ì‚¬ìš© ì˜ˆì‹œ
# ========================================

if __name__ == "__main__":
    # ì„¤ì •
    IMAGE_FOLDER = "../thumbnails_image/raw_thumbnails"
    OUTPUT_DIR = "../rawData/thumbnails"
    # Google Cloud ì¸ì¦ íŒŒì¼ ê²½ë¡œ (í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© ê¶Œì¥)
    GOOGLE_CREDENTIALS = os.getenv("GOOGLE_APPLICATION_CREDENTIALS", "./credentials/google-vision-api.json")
    
    # í†µí•© ì¶”ì¶œ
    extractor = ThumbnailFeatureExtractor(google_credentials_path=GOOGLE_CREDENTIALS)
    
    results = extractor.extract_all_features(
        image_folder=IMAGE_FOLDER,
        output_dir=OUTPUT_DIR,
        extract_text=True,
        extract_colors=True,
        extract_visual=True
    )
    
    print("\nğŸ“Š ì¶”ì¶œëœ í”¼ì²˜:")
    for key, df in results.items():
        print(f"  - {key}: {len(df)} rows")
